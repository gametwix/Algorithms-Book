% Ивенкова
\chapter*{Глава 15: Применение динамического программирования}

\vspace{\baselineskip}
Основная идея динамического программирования заключается в разбиении трудной задачи на несколько маленьких, простых и многократно встречающихся задач. Если в задаче отчетливо заметна простая многократно решаемая подзадача, вполне возможно, что к ней можно применить данный подход.

\vspace{\baselineskip}
В силу того, что заголовок этой главы содержит слово {\itshape «применение»}, упор в ней сделан скорее на применения, чем на процесс создания алгоритмов.

\vspace{\baselineskip}
\section*{Раздел 15.1: Числа Фибоначчи}

\vspace{\baselineskip} 
\href{https://vk.cc/atMGsz}{\underline{Числа Фибоначчи}} прекрасно демонстрируют принцип динамического программирования, поскольку традиционный рекурсивный подход к ним задействует множество повторяющихся вычислений. В этих примерах я буду стандартно полагать f(\p{0}) = f(\p{1}) = \p{1}.

\vspace{\baselineskip}
Ниже представлен пример рекурсивного дерева для числа Фибоначчи (\p{4}), обратите внимание на повторяющиеся вычисления:

\includeimage{0.7}{images/78.pdf}

\vspace{\baselineskip}
\textbf{Нединамическое программирование} О($2^n$) временная сложность алгоритма, О(n) сложность стека 

\vspace{\baselineskip}
\begin{tcolorbox}
\begin{minted}{Python}
def fibonacci(n):	   # функция по вычислению числа фибоначчи
	if n < 2: # для чисел из заданного промежутка возможен только один результат
	return 1	
return fibonacci(n-1) + fibonacci(n-2) # рекурсивный вызов функции
\end{minted}
\end{tcolorbox}

\vspace{\baselineskip}
Это самый интуитивный способ написать решение. В большинстве случае стековое пространство будет О(n) по мере спуска по первой рекурсивной ветви вызовов fibonacci(n-\p{1}) до случая n < \p{2}.

\vspace{\baselineskip}
Доказательство оценки временной сложности можно посмотреть тут: \newline\href{https://stackoverflow.com/questions/360748/computational-complexity-of-fibonacci-sequence}{\underline{вычислительная сложность последовательности Фибоначчи}}. Основное внимание стоит уделить тому, что сложность экспоненциальная, иными словами, время выполнения программы удваивается с каждым последующим числом, например, f(\p{15}) будет вычисляться вдвое дольше, чем f(\p{14}). 

\vspace{\baselineskip}
\textbf{Мемоизированная} за О(n) временная сложность алгоритма, О(n) сложность пространства, О(n) стековая сложность

\vspace{\baselineskip}
\begin{tcolorbox}
\begin{minted}{Python}
memo = []  # создадим массив для записи в него вычисляемых чисел фибоначчи
# добавим в массив два первых числа, необходимых для вычисления последующих
memo.append(1) # f(1) = 1
memo.append(1) # f(2) = 1
def fibonacci(n):
	if len(memo) > n: # проверим не находили ли мы значение данного числа ранее
		return memo[n] # если мы уже находили значение текущего числа, то просто 
					   # выводим его
	result = fibonacci(n-1) + fibonacci(n-2) # вычисляем результат и записываем 
	# значение в массив для уменьшения количества вычислений в будущем
	memo.append(result) # f(n) = f(n-1) + f(n-2)
	return result
\end{minted}
\end{tcolorbox}

\vspace{\baselineskip}
В этом случае мы вводим массив, который можно считать состоящим из всех предыдущих вызовов функции. В ячейке memo[n] хранится результат вызова fibonacci(n). Это позволяет нам ценой сложности пространства О(n) уменьшить временную сложность, поскольку нам не придется вычислять повторные вызовы лишний раз.

\vspace{\baselineskip}
\textbf{Итеративное динамическое программирование} О(n) временная сложность, O(n) сложность пространства, рекурсивный стек отсутствует

\vspace{\baselineskip}
\begin{tcolorbox}
\begin{minted}{Python}
def fibonacci(n):
# создадим массив и добавим в него два первых числа
	memo = [1,1] # f(0) = 1, f(1) = 1
	for i in range(2, n+1):
		 memo.append(memo[i-1] + memo[i-2]) # циклично вычисляем значения чисел 
											# фибоначчи и добавляем их в массив
	return memo[n] # возвращаем искомое число
\end{minted}
\end{tcolorbox}

\vspace{\baselineskip}
Сведя задачу к основаниям, читатель может заметить, что для вычисления fibonacci(n) необходимо вычислить fibonacci(n-\p{1}) и fibonacci(n-\p{2}). Также он может заметить, что базовый случай возникает в конце того рекурсивного дерева, изображенного выше. 

\vspace{\baselineskip}
Со знанием этого, имеет смысл вычислять ответ "задом наперед", начиная с базовых значенийи поднимаясь выше. Теперь для вычисления fibonacci(n) потребуется вычислить \textbf{все} числа Фибоначчи до n-го включительно.

\vspace{\baselineskip}
Главным достоинством является то, что теперь мы устранили рекурсивный стек, сохранив временную сложность O(n). Но, к сожалению, изменение пространственной сложности потребует отдельной заботы.

\vspace{\baselineskip}
\textbf{Улучшенное итеративное динамическое программирование} О(n) временная сложность, О(1) пространственная сложность, рекурсивный стек отсутствует

\vspace{\baselineskip}
\begin{tcolorbox}
\begin{minted}{Python}
def fibonacci(n):
# создадим массив и добавим в него два первых числа
	memo = [1,1] # f(0) = 1, f(1) = 1
	for i in range(2, n):
		memo[i%2] = memo[0] + memo[1] # заполняем массив числами, 
									  # предшествующими искомому
	return memo[n%2] # возвращаем искомое число
\end{minted}
\end{tcolorbox}

\vspace{\baselineskip}
Как сказано выше, итеративное динамическое программирование делает свое дело, начиная с базовых случаев, поднимаясь к окончательному результату. Ключевое наблюдение, необходимое для получения пространственной сложности О(\p{1}), аналогично наблюдению, проявленному в рекурсивном случае: нам необходимо знать лишь fibonacci(n-\p{1}) и fibonacci(n-\p{2}) для вычисления fibonacci(n). Это означает, что в любой момент работы программы нам необходимо хранить в памяти лишь два предыдущих значения.

\vspace{\baselineskip}
Чтобы хранить эти два значения я использую двухэлементный массив и обращаюсь к нему путем взятия остатка от деления на два индекса i, меняющегося следующим образом: \p{0}, \p{1}, \p{0}, \ldots, i \% \p{2}.

\vspace{\baselineskip}
Я добавляю оба индекса массива поскольку все мы знаем, что сложение коммутативно (\p{5}+ \p{6} = \p{11} and \p{6} + \p{5} == \p{11}). Результат записывается затем в ячейку, к которой мы обращались в предпоследний раз (обозн. i \% \p{2}).  Окончательный ответ будет записан в позицию n\%2.

\vspace{\baselineskip}
\textbf{Замечание}

\vspace{\baselineskip}
\begin{itemize}
  \item Важно понимать, что иногда бывает правильнее использовать итеративное мемоизированное решение для функций, которые выполняют огромные повторяющиеся вычисления, поскольку в таком случае последующие обращения к этим функциям будут иметь сложность О(\p{1}), как уже вычисленные ввиду  кэширования ответа.
\end{itemize}

\chapter*{Глава 16. Алгоритм Крускала}

\vspace{\baselineskip}
\section*{Раздел 16.1: Оптимальное применение на основе непересекающихся множеств.}

\vspace{\baselineskip}
Есть два способа улучшить простые и субоптимальные не пересекающиеся множественные подалгоритмы:

\vspace{\baselineskip}
\begin{enumerate}
    \item \textbf{Эвристика сжатия путей:} findSet не нуждается в обработке дерева, высота которого больше двух. В случае необходимости она может связать нижние узлы напрямую с корнем, оптимизируя будущие трансверсали: 
	
	\vspace{\baselineskip}
	\begin{tcolorbox}
	\begin{minted}{Python}
subalgo findSet(v: a node):
if v.parent != v
	v.parent = findSet(v.parent)# функция рекурсивно проходит от любого 
								# узла к корню
return v.parent
    \end{minted}
    \end{tcolorbox}
    
    \item \textbf{Перемешивание, основанное на высоте}: для каждого узла хранится высота его поддерева. При перемешивании нужно сделать более высокое дерево родителем менее высокого, не увеличивая высоту того или иного дерева.
    
    \vspace{\baselineskip}
    \begin{tcolorbox}
    \begin{minted}{Python}
subalgo unionSet(u, v: nodes):
# свяжем два узла с их корнями
vRoot = findSet(v)
uRoot = findSet(u)
if vRoot == uRoot: # проверим, чтобы два узла не совпадали
	return
if vRoot.height < uRoot.height: # согласно функции поиска корня при 
# выполнении данного условия один из корней будет родителем второго
	vRoot.parent = uRoot
else if vRoot.height > uRoot.height: # согласно функции поиска корня при 
# выполнении данного условия один из корней будет родителем второго
	uRoot.parent = vRoot
else:
	uRoot.parent = vRoot # если не выполняются оба условия будем считать 
						 # один из корней родителем другого по умолчанию
	uRoot.height =  uRoot.height + 1
    \end{minted}
    \end{tcolorbox} 
    
\end{enumerate}

\vspace{\baselineskip}
Это приводит к времени выполнения 0(alpha(n)) для каждой операции, где alpha - обратная функция к быстро возрастающей функции Аккермана. Таким образом, ее собственный рост крайне замедлен и может считаться за O(\p{1})  в практических целях.

\vspace{\baselineskip}
Благодаря этому и начальной сортировке, для всего алгоритма Крускала верно O(m log m + m) = O(m log m),. 

\vspace{\baselineskip}
\textbf{Замечание}

\vspace{\baselineskip}
Сжатие путей может уменьшить высоту дерева, что сильно усложняет сравнение высот деревьев в процессе объединения. Во избежание трудностей с хранением и вычислением высот деревьев результирующий родитель может быть выбран случайным образом: 

\vspace{\baselineskip}
\begin{tcolorbox}
\begin{minted}{Python}
subalgo unionSet(u, v: nodes):
# свяжем два узла с их корнями
		vRoot = findSet(v)
		uRoot = findSet(u)
		if vRoot == uRoot:  # проверим, чтобы два узла не совпадали
			return
		if random() % 2 == 0: # выберем родителя случайным образом
			vRoot.parent = uRoot
		else:
			uRoot.parent = vRoot
\end{minted}
\end{tcolorbox}

\vspace{\baselineskip}
На практике такой алгоритм в сочетании со сжатием путей для операции findSet будет выдавать сравнимый результат при гораздо более простом использовании. 

\vspace{\baselineskip}
\section*{Раздел 16.2: Простое, более детальное использование}

\vspace{\baselineskip}
Чтобы эффективно справляться с обнаружением циклов, будем считать каждый узел частью дерева. По мере добавления ребра определяем, являются ли компонентные узлы частями различных деревьев.

\vspace{\baselineskip}
\begin{tcolorbox}
\begin{minted}{Python}
algorithm kruskalMST(G: a graph)
	sort Gs edges by their value 
# отсортируем Gs ребра  по их значению
	MST = a forest of trees, initially each tree is a node in the graph 
# MST = лес деревьев, изначально каждое дерево является узлом графа
	for each edge e in G: #  для каждого ребра в G:
		if the root of the tree that e.first belongs to is not the same
# если корень дерева, к которому принадлежит e.first, не совпадает
		as the root of the tree that e.second belongs to: 
# как корень дерева, к которому принадлежит e.second:
			connect one of the roots to the other, thus merging two trees
# соединить один из корней с другим, таким образом объединяя два дерева
		return MST, which now a single-tree forest
# вернуть MST, который теперь представляет из себя лес с одним деревом
\end{minted}
\end{tcolorbox}

\vspace{\baselineskip}
\section*{Раздел 16.3: Простое использование, основанное на непересекающихся множествах}

\vspace{\baselineskip}
Вышеупомянутая лесная методология на самом деле является системой непересекающихся множеств, использующей три главных операции:

\vspace{\baselineskip}
\begin{tcolorbox}
\begin{minted}{Python}
subalgo makeSet(v: a node):  # создаём поддерево
	v.parent = v	# создаём поддерево с корнем v
   
subalgo findSet(v: a node): # находим корень узла по уже известной функции
	if v.parent == v:
		return v
	return findSet(v.parent)

subalgo unionSet(v, u: nodes): # для двух корней определим иерархию
	vRoot = findSet(v)
	uRoot = findSet(u)
	uRoot.parent = vRoot

algorithm kruskalMST(G: a graph):
	sort Gs edges by their value # отсортируем Gs грани по их значениям
	for each node n in G: # для каждого узла создадим поддерево
		makeSet(n)
	for each edge e in G: # если узлы не принадлежат к одному корню, объединим 
						 # деревья
		if findSet(e.first) != findSet(e.second):
			unionSet(e.first, e.second)
\end{minted}
\end{tcolorbox}

\vspace{\baselineskip}
Время для управления системой непересекающихся множеств занимает при наивном использовании 0(n log n), таким образом время работы всего алгоритма Крускала составляет O(m*n log n).

\vspace{\baselineskip}
\section*{Раздел 16.4: Простое высокоуровневое использование}

\vspace{\baselineskip}
Сортируем ребра по величине и добавляем их в MST в отсортированном порядке, если они не образуют цикл. 

\vspace{\baselineskip}
\begin{tcolorbox}
\begin{minted}{Python}
algorithm kruskalMST(G: a graph)
	sort Gs edges by their value # отсортируем Gs ребра  по их значению
	MST = an empty graph # MST = пустой граф
	for each edge e in G: # для каждого ребра в G:
		if adding e to MST does not create a cycle:
# если добавление e в MST не создает цикл:
			add e to MST # добавим е к MST
    return MST
\end{minted}
\end{tcolorbox}

\chapter*{Глава 17: Жадные алгоритмы}

\vspace{\baselineskip}
\section*{Раздел 17.1: Кодировка Хаффмана}

\vspace{\baselineskip}
\href{https://vk.cc/atQr71}{\underline{Код Хаффмана}} --- это особый тип оптимального префиксного кода, который повсеместно используется для сжатия данных без потерь. Он сжимает данные крайне эффективно, экономя от 20\% до 90\% памяти, в зависимости от характеристики сжимаемых данных. Здесь мы считаем данными символьные последовательности. Жадный алгоритм Хаффмана использует таблицу частот возникновения того или иного символа в последовательности, оптимально представляя каждый символ в виде бинарной строки. Код Хаффмана был предложен \href{https://vk.cc/atQreq}{\underline{Дэвидом А. Хаффманом}} в 1951 году.  

\vspace{\baselineskip}
Предположим, у нас есть файл с данными в виде 100000 символов, который мы хотели бы сжать. Предположим, что в файле встречаются только шесть различных символов. Ниже приведена частота их появления: 

\vspace{\baselineskip}
\begin{tcolorbox}
\begin{verbatim}
+------------------------+-----+-----+-----+-----+-----+-----+
|        Character       |  a  |  b  |  c  |  d  |  e  |  f  |
+------------------------+-----+-----+-----+-----+-----+-----+
|Frequency (in thousands)|  45 |  13 |  12 |  16 |  9  |  5  |
+------------------------+-----+-----+-----+-----+-----+-----+
\end{verbatim}
\end{tcolorbox}


\vspace{\baselineskip}
Мы располагаем многочисленными способами представить такой файл. Здесь мы рассмотрим задачу составления {\itshape бинарного символьного кода}, в котором каждый символ будет представляться бинарной строкой, называемой \textbf{
кодовым словом}. 

\includeimage{0.4}{images/84.pdf}

\newpage
Благодаря построенному дереву мы видим, что:

\vspace{\baselineskip}
\begin{tcolorbox}
\begin{verbatim}
+------------------------+-----+-----+-----+-----+-----+-----+
|        Character       |  a  |  b  |  c  |  d  |  e  |  f  |
+------------------------+-----+-----+-----+-----+-----+-----+
| Fixed-length Codeword  | 000 | 001 | 010 | 011 | 100 | 101 |
+------------------------+-----+-----+-----+-----+-----+-----+
|Variable-length Codeword|  0  | 101 | 100 | 111 | 1101| 1100|
+------------------------+-----+-----+-----+-----+-----+-----+
\end{verbatim}
\end{tcolorbox}

\vspace{\baselineskip} Если мы используем \textbf{код фиксированной длины}, нам потребуется 3 бита для представления 6 символов. Такой метод потребует 300000 бит для кодирования всего файла.А можем ли мы улучшить положение?